{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Masked Autoencoders: Visualization Demo"
      ],
      "metadata": {
        "id": "CynZ1tB0qHt6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1Y9_3ilVLQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare\n"
      ],
      "metadata": {
        "id": "SjZ2Ct1rqMt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9pH7vM4cU3Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# check whether run in Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    print('Running in Colab.')\n",
        "    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n",
        "    !git clone https://github.com/sysu19351176/Change_Detection_MAE.git\n",
        "    sys.path.append('./mae')\n",
        "else:\n",
        "    sys.path.append('..')\n",
        "import models_mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "LYjTZBc-qR3a",
        "outputId": "b203de82-bef8-4cf1-e845-770cd424448f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.5\n",
            "  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm==0.4.5) (0.15.1+cu118)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/dist-packages (from timm==0.4.5) (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.5) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.5) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.5) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.5) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.5) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.5) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.5) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.5) (3.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm==0.4.5) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->timm==0.4.5) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm==0.4.5) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4->timm==0.4.5) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.4.5) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.4.5) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.4.5) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.4.5) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4->timm==0.4.5) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.5\n",
            "Cloning into 'Change_Detection_MAE'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 44 (delta 0), reused 0 (delta 0), pack-reused 42\u001b[K\n",
            "Unpacking objects: 100% (44/44), 867.96 KiB | 7.82 MiB/s, done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0309d816322f>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels_mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models_mae'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define utils"
      ],
      "metadata": {
        "id": "zBgZ0Mxsu9wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the utils\n",
        "\n",
        "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
        "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def show_image(image, title=''):\n",
        "    # image is [H, W, 3]\n",
        "    assert image.shape[2] == 3\n",
        "    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.axis('off')\n",
        "    return\n",
        "\n",
        "def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):\n",
        "    # build model\n",
        "    model = getattr(models_mae, arch)()\n",
        "    # load model\n",
        "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
        "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
        "    print(msg)\n",
        "    return model\n",
        "\n",
        "def run_one_image(imgt1,imgt2,img_label,model):\n",
        "    x_t1 = torch.tensor(imgt1)\n",
        "    x_t2=torch.tensor(imgt2)\n",
        "    x_label=torch.tensor(img_label)\n",
        "\n",
        "\n",
        "    # make it a batch-like\n",
        "    x_t1 = x_t1.unsqueeze(dim=0)\n",
        "    x_t1 = torch.einsum('nhwc->nchw', x_t1)\n",
        "\n",
        "    x_t2 = x_t2.unsqueeze(dim=0)\n",
        "    x_t2 = torch.einsum('nhwc->nchw', x_t2)\n",
        "\n",
        "    x_label = x_label.unsqueeze(dim=0)\n",
        "    x_label = torch.einsum('nhwc->nchw', x_label)\n",
        "\n",
        "    # run MAE\n",
        "    loss, y, mask = model(x_t1.float(), x_t2.float(),x_label.float())\n",
        "    y = model.unpatchify(y)\n",
        "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
        "\n",
        "    # visualize the mask\n",
        "    mask = mask.detach()\n",
        "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n",
        "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
        "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
        "    \n",
        "    x = torch.einsum('nchw->nhwc', x)\n",
        "\n",
        "    # masked image\n",
        "    im_masked = x * (1 - mask)\n",
        "\n",
        "    # MAE reconstruction pasted with visible patches\n",
        "    im_paste = x * (1 - mask) + y * mask\n",
        "\n",
        "    # make the plt figure larger\n",
        "    plt.rcParams['figure.figsize'] = [24, 24]\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    show_image(x[0], \"original\")\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    show_image(im_masked[0], \"masked\")\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    show_image(y[0], \"reconstruction\")\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    show_image(im_paste[0], \"reconstruction + visible\")\n",
        "\n",
        "    plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "W8TwL12ar7jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load an image"
      ],
      "metadata": {
        "id": "Mjjwo-fCu_8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load an image\n",
        "img_label = 'https://uc78c92a63fd851f38bd835aabf1.previews.dropboxusercontent.com/p/thumb/AB1U5YAbVbuOfTvFY969B1xJ4Fg9wQbwPDW9jUjwtZGRNqY8O-dHYDqoun-8nFZPJWIlCTJ06IfP7lFm7a0qkReu7okYxkGafK-Q-T-OcGuCqtrhhVZKLJzFXdRxlaKiG6DeiT-VFKuDIrnHXQFGf9JV86Eu1zr_R1AN7z6GZmstckAUAQme1duCGROdkhNPkW4yenjHQNXb6L8Ng3nqZ_CAvWNziaiEGrpDpJhnjqNNAyK44OsjCmdgN0YTeWDazU-IQKyhsIY72mtEJfRsIu-vwnrU2C9tWVtQG28pxVkgssqQNBpoE_JoWKvEvO-YqIRyP34rhFdjNyx3e9peA1kU3u1dh0nNG-jiBJKZek-Pf1bi0SCV9rxyCK0sza5j4AA/p.png' # from LEVIR-CD256\n",
        "img_t1_url = 'https://uc65bd97fb2efd30aa82a917f0da.previews.dropboxusercontent.com/p/thumb/AB3JhQPRZZo1G8N8f4J4Ff0jLEgwUCdiuCZcgkMQax_QAOf_U2GZtsX1sDP827daEwfopipFifOSddnXwM0SrqcupcZ_gE5FCCTVCO93XgnglkhI5hz_OPRVISsDuQ_-S6BzkVk_XH_L6IUjGJ1UEHmDzs9INRSN84g_5BG6T2V5PN-HgavsNXRVxmN94iJIa6AssImCwO8kOCYTRyLPLZZ8UdM8-9Ux5f7Z_rYnlLJ1uoSvMVsMCx2KTYwealnhDgR5Wb-_dkAMeHc9ply_NGBTXrubY1-WJGTppsOwxB2Ua6zSjk7Mj5mCXdtkk5Wz1R6Mn1cp5qW_3fPVGh_qFmCzMBBOrvXgFTXiWp9_nVgda-iIfyxyYbmqwqeeTVGSA3TBMO6vof_E2qIdxtJ1anzU/p.png?size=512x512&size_mode=1' \n",
        "img_t2_url ='https://uc517512112389a6ff959acb5f0e.previews.dropboxusercontent.com/p/thumb/AB1UclKlzzcY0B93FUMREDi0yWBqo_H7ZvliJuVAVcxz7kNVCHsJuvpUYiFVuDzFcrz_zCrG-JfWjqZWB_ROeo7SYu0uDI9AtES0fBWXsh--KbTOyRibpPLuJxB1jDGDdtOU0MNjtAj0Dzb6oTsOqYmKuAdmqeHcnD_4VA27_SxsH7ezN8CjqShCmshTGer5VYkfDtPNIEd_vAFRgXw77ylAJs6u2oa9H8CpfJaFTPysUYZaXuk3thKS2t7VRsX7vM2y98V9mHwrv0VsOVzYT97zXD3dhxXBun2YtuR2n1vHwXb0udvuZYaJCqyVx_gVLI4yZdX_x0gJ3wl6DWHs5pN4yi3t-K2TRv8ALnjqqJc6nQWpgKJ07deK61sK4ip-XaA/p.png'\n",
        "img_t1 = Image.open(requests.get(img_t1_url, stream=True).raw)\n",
        "img_t1 = img_t1.resize((256, 256))\n",
        "img_t1 = np.array(img_t1) / 255.\n",
        "\n",
        "img_t2 = Image.open(requests.get(img_t2_url, stream=True).raw)\n",
        "img_t2 = img_t2.resize((256, 256))\n",
        "img_t2 = np.array(img_t2) / 255.\n",
        "\n",
        "assert img_t1.shape == (256, 256, 3) and img_t1.shape == (256, 256, 3)\n",
        "\n",
        "# normalize by ImageNet mean and std\n",
        "img_t1 = img_t1 - imagenet_mean\n",
        "img_t1 = img_t1 / imagenet_std\n",
        "\n",
        "img_t2 = img_t2 - imagenet_mean\n",
        "img_t2 = img_t2 / imagenet_std\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [5, 5]\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "show_image(img_t1, \"Tl\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "show_image(img_t2, \"T2\")\n",
        "\n"
      ],
      "metadata": {
        "id": "h9yjgNS8t9eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a pre-trained MAE model"
      ],
      "metadata": {
        "id": "QSKHtpoPvD2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an MAE model trained with pixels as targets for visualization (ViT-Large, training mask ratio=0.75)\n",
        "\n",
        "# download checkpoint if not exist\n",
        "!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth\n",
        "\n",
        "chkpt_dir = 'mae_visualize_vit_large.pth'\n",
        "model_mae = prepare_model(chkpt_dir, 'mae_vit_large_patch16')\n",
        "print('Model loaded.')\n"
      ],
      "metadata": {
        "id": "72ExXDVuuE3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run MAE on the image"
      ],
      "metadata": {
        "id": "XYp1h5esvJE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make random mask reproducible (comment out to make it change)\n",
        "torch.manual_seed(2)\n",
        "print('MAE with pixel reconstruction:')\n",
        "run_one_image(img, model_mae)"
      ],
      "metadata": {
        "id": "3TlbSD2ou4pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load another pre-trained MAE model"
      ],
      "metadata": {
        "id": "aFZhpiH_vQTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an MAE model trained with an extra GAN loss for more realistic generation (ViT-Large, training mask ratio=0.75)\n",
        "\n",
        "# download checkpoint if not exist\n",
        "!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large_ganloss.pth\n",
        "\n",
        "chkpt_dir = 'mae_visualize_vit_large_ganloss.pth'\n",
        "model_mae_gan = prepare_model('mae_visualize_vit_large_ganloss.pth', 'mae_vit_large_patch16')\n",
        "print('Model loaded.')"
      ],
      "metadata": {
        "id": "6fq3TlQovWQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run MAE on the image"
      ],
      "metadata": {
        "id": "wQkQNPmIvZc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make random mask reproducible (comment out to make it change)\n",
        "torch.manual_seed(2)\n",
        "print('MAE with extra GAN loss:')\n",
        "run_one_image(img, model_mae_gan)"
      ],
      "metadata": {
        "id": "oXd9UjSnveui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1W5LEs6sp7jT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U1RGcUkWvdcD"
      }
    }
  ]
}